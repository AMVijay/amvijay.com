<html>
<head>
	<!-- Global site tag (gtag.js) - Google Analytics -->
	<script async src="https://www.googletagmanager.com/gtag/js?id=UA-27752939-2"></script>
	<script>
	  window.dataLayer = window.dataLayer || [];
	  function gtag(){dataLayer.push(arguments);}
	  gtag('js', new Date());

	  gtag('config', 'UA-27752939-2');
	</script>
	<!-- Required meta tags -->
	<meta charset="utf-8">
	<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
	<!-- Bootstrap CSS -->
	<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/css/bootstrap.min.css"
	crossorigin="anonymous">
	<!-- Optional JavaScript -->
	<!-- jQuery first, then Popper.js, then Bootstrap JS -->
	<script src="https://code.jquery.com/jquery-3.4.1.min.js" crossorigin="anonymous"></script>
	<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.12.9/umd/popper.min.js"
	crossorigin="anonymous"></script>
	<script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/js/bootstrap.min.js" crossorigin="anonymous"></script>
	<!-- Meta Tags --> 
	<title>Hadoop Installation And Setup Steps</title>
	<meta name="description" content="Hadoop Installation and Setup in Linux Debian/Ubuntu" />
</head>
<body style="min-height: 75rem; padding-top: 4.5rem;">
	<div id="header">
		<nav class="navbar navbar-expand-md navbar-light fixed-top" style="background-color: #8fc1e3;">
		  <a class="navbar-brand" href="/">AM.VIJAY</a>
		  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNavDropdown"
			aria-controls="navbarNavDropdown" aria-expanded="false" aria-label="Toggle navigation">
			<span class="navbar-toggler-icon"></span>
		  </button>
		  <div class="collapse navbar-collapse" id="navbarNavDropdown">
			<ul class="navbar-nav">
			  <li class="nav-item active">
				<a class="nav-link" href="/">Home</a>
			  </li>
			</ul>
		  </div>
		</nav>	
	</div>
	<div id="content" class="container">

<h1 id="hadoop-installation-and-setup">Hadoop Installation and Setup</h1>
<p>Last Updated On 02/20/2020</p>
<h2 id="linux-update-the-package-version-and-upgrade">Linux : Update the Package Version and Upgrade</h2>
<p>Below commands can be used to update linux package version in local repository and upgrade:</p>
<ul>
<li><code>sudo apt update</code>  </li>
<li><code>sudo apt upgrade</code><br>To know the list of packages upgradable in linux, use command <code>apt list --upgradable</code></li>
</ul>
<h2 id="install-ssh-service-in-linux">Install SSH Service in Linux</h2>
<ul>
<li>Install using command <code>sudo apt install ssh</code> </li>
<li>To start/stop or restart the ssh service, use command <code>sudo service ssh restart</code></li>
</ul>
<h2 id="download-and-configure-hadoop-binaries-installation">Download and Configure Hadoop Binaries Installation</h2>
<ul>
<li>Install wget in linux using command <code>sudo apt install wget</code>, if not already installed.  </li>
<li>Download the hadoop binaries using wget command <code>wget &lt;hadoop tar http path&gt;</code> <ul>
<li>Example <code>wget http://mirror.cogentco.com/pub/apache/hadoop/common/hadoop-3.2.1/hadoop-3.2.1.tar.gz --no-check-certificate</code></li>
<li>If required perform checksum for reliability, if required add option <code>--no-check-certificate</code>  </li>
</ul>
</li>
<li>Extract the hadoop binaries using command <code>tar -xzvf hadoop-3.2.1.tar.gz</code>   <ul>
<li>Here, x denotes EXTRACT, z denotes GZIP, v denotes VERBOSE, f denotes FILE.  </li>
</ul>
</li>
<li>Move the hadoop binaries folder to <code>/usr/local</code> directory using command <code>sudo mv hadoop-3.2.1 /usr/local/hadoop-3.2.1</code></li>
<li>Create softlink <code>/usr/local/hadoop</code> to the hadoop version using command <code>sudo ln -s /usr/local/hadoop-3.2.1 /usr/local/hadoop</code> <ul>
<li>In case if we install another version of hadoop, just need to update the softlink so that all scripts will retain intact. </li>
</ul>
</li>
</ul>
<h2 id="download-and-configure-jdk-jre">Download And Configure JDK/JRE</h2>
<p><code>sudo apt install default-jre</code> - This normally installs the Java in /usr/lib/jvm/<jdk folder>, and updates the softlink of /usr/bin/java to the installable.
<code>sudo apt install default-jdk</code> -<br><code>sudo update-java-alternatives --list</code> or  <code>sudo update-alternatives --config java</code> - (This is list down all java installable and its path in the os, we can select default JRE in the OS for all users)<br>Or<br>To Install precise JDK 8 Version, follow the steps detailed below.  </p>
<ul>
<li>Download the latest JDK8 from AWS using command 
  <code>wget https://corretto.aws/downloads/latest/amazon-corretto-8-x64-linux-jdk.tar.gz --no-check-certificate</code></li>
<li>Extract the JDK 8 binary using command <code>tar -xzvf amazon-corretto-8-x64-linux-jdk.tar.gz</code></li>
<li>Move the JDK 8 binaries to <code>sudo mv amazon-corretto-8.242.07.1-linux-x64/ /usr/local/amazon-corretto-8.242.07.1-linux-x64</code></li>
<li>Create softlink as <code>sudo ln -s /usr/local/amazon-corretto-8.242.07.1-linux-x64 /usr/local/jdk8</code></li>
</ul>
<p>Update <code>sudo nano /etc/profile</code> as below, so that JAVA_HOME will set in OS level.</p>
<pre><code class="lang-bash"><span class="hljs-comment"># JAVA PATH Settings</span>
<span class="hljs-built_in">export</span> JAVA_HOME=/usr/<span class="hljs-built_in">local</span>/jdk8
<span class="hljs-built_in">export</span> PATH=<span class="hljs-variable">$PATH</span>:<span class="hljs-variable">$JAVA_HOME</span>/bin
</code></pre>
<h2 id="update-bashrc-in-user-profile-as-below">Update .bashrc in user profile as below</h2>
<pre><code class="lang-bash"><span class="hljs-comment"># Added for HADOOP</span>
<span class="hljs-built_in">export</span> JAVA_HOME=/usr/<span class="hljs-built_in">local</span>/jdk8
<span class="hljs-built_in">export</span> PATH=<span class="hljs-variable">$PATH</span>:<span class="hljs-variable">$JAVA_HOME</span>/bin

<span class="hljs-built_in">export</span> HADOOP_HOME=/usr/<span class="hljs-built_in">local</span>/hadoop
<span class="hljs-built_in">export</span> PATH=<span class="hljs-variable">$PATH</span>:<span class="hljs-variable">$HADOOP_HOME</span>/bin:<span class="hljs-variable">$HADOOP_HOME</span>/sbin
</code></pre>
<p>Execute command <code>source .bashrc</code> - This command will apply all the changes to current running bash session. Source command will make all the changes applied to current running session.</p>
<h2 id="update-hadeep-env-sh-in-hadoop">Update hadeep-env.sh in Hadoop</h2>
<p>Update the hadoop environment setup file <code>sudo nano /usr/local/hadoop/etc/hadoop/hadoop-env.sh</code> with JAVA_HOME AND HADOOP_HOME as below</p>
<ul>
<li><code>export JAVA_HOME=/usr/local/jdk8</code></li>
<li><code>export HADOOP_HOME=/usr/local/hadoop/</code>  </li>
</ul>
<p>Add the USER ID configuration parameter to <code>/usr/local/hadoop/etc/hadoop/hadoop-env.sh</code> as below</p>
<pre><code class="lang-bash"><span class="hljs-comment"># HADOOP PROCESS USER ID</span>
<span class="hljs-built_in">export</span> HDFS_NAMENODE_USER=admin
<span class="hljs-built_in">export</span> HDFS_DATANODE_USER=admin
<span class="hljs-built_in">export</span> HDFS_SECONDARYNAMENODE_USER=admin
<span class="hljs-built_in">export</span> YARN_RESOURCEMANAGER_USER=admin
<span class="hljs-built_in">export</span> YARN_NODEMANAGER_USER=admin
</code></pre>
<h2 id="run-mapreduce-algorithm">Run MapReduce Algorithm</h2>
<p><code>mkdir ~/input</code><br><code>cp /usr/local/hadoop/etc/hadoop/*.xml ~/input</code><br><code>/usr/local/hadoop/bin/hadoop jar /usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.2.jar grep ~/input ~/grep_example &#39;allowed[.]*&#39;</code><br>    If ~/grep_example already exists, then delete the folder <code>rm -ef ~/grep_example</code>  </p>
<p><code>cat ~/grep_example/*</code> to check the output of mapandreduce  </p>
<h2 id="ssh-key-configuration">SSH key Configuration</h2>
<p><code>ssh-keygen -t rsa -P &#39;&#39; -f ~/.ssh/id_rsa</code><br><code>cat ~/.ssh/id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys</code><br><code>chmod 0600 ~/.ssh/authorized_keys</code></p>
<h2 id="modify-configuration">Modify Configuration</h2>
<ul>
<li>Change <code>sudo nano /usr/local/hadoop/etc/hadoop/core-site.xml</code> as  <pre><code class="lang-xml"><span class="hljs-tag">&lt;<span class="hljs-name">configuration</span>&gt;</span>
  <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span>
      <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>fs.defaultFS<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span>
      <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>hdfs://localhost:9000<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span>
  <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span>
<span class="hljs-tag">&lt;/<span class="hljs-name">configuration</span>&gt;</span>
</code></pre>
</li>
<li>Change <code>sudo nano /usr/local/hadoop/etc/hadoop/hdfs-site.xml</code> as  <pre><code class="lang-xml"><span class="hljs-params">&lt;configuration&gt;</span>
  <span class="hljs-params">&lt;property&gt;</span>
      <span class="hljs-params">&lt;name&gt;</span>dfs.replication<span class="hljs-params">&lt;/name&gt;</span>
      <span class="hljs-params">&lt;value&gt;</span><span class="hljs-number">1</span><span class="hljs-params">&lt;/value&gt;</span>
  <span class="hljs-params">&lt;/property&gt;</span>
  <span class="hljs-params">&lt;property&gt;</span>
      <span class="hljs-params">&lt;name&gt;</span>dfs.namenode.name.dir<span class="hljs-params">&lt;/name&gt;</span>
      <span class="hljs-params">&lt;value&gt;</span><span class="hljs-meta-keyword">/home/</span>admin<span class="hljs-meta-keyword">/hadoop/</span>data/namenode<span class="hljs-params">&lt;/value&gt;</span>
  <span class="hljs-params">&lt;/property&gt;</span>
  <span class="hljs-params">&lt;property&gt;</span>
      <span class="hljs-params">&lt;name&gt;</span>dfs.datanode.data.dir<span class="hljs-params">&lt;/name&gt;</span>
      <span class="hljs-params">&lt;value&gt;</span><span class="hljs-meta-keyword">/home/</span>admin<span class="hljs-meta-keyword">/hadoop/</span>data/datanode<span class="hljs-params">&lt;/value&gt;</span>
  <span class="hljs-params">&lt;/property&gt;</span>
<span class="hljs-params">&lt;/configuration&gt;</span>
</code></pre>
</li>
<li>Change <code>sudo nano /usr/local/hadoop/etc/hadoop/yarn-site.xml</code> as <pre><code class="lang-xml"><span class="hljs-tag">&lt;<span class="hljs-name">configuration</span>&gt;</span>
 <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span>
    <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span>
    <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>mapreduce_shuffle<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span> 
 <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span>
<span class="hljs-tag">&lt;/<span class="hljs-name">configuration</span>&gt;</span>
</code></pre>
</li>
<li>Change <code>sudo nano /usr/local/hadoop/etc/hadoop/mapred-site.xml</code> as <pre><code class="lang-xml"><span class="hljs-tag">&lt;<span class="hljs-name">configuration</span>&gt;</span>
  <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span> 
    <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>mapreduce.framework.name<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span>
    <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>yarn<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span>
 <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span>
<span class="hljs-tag">&lt;/<span class="hljs-name">configuration</span>&gt;</span>
</code></pre>
</li>
</ul>
<h2 id="start-stop-the-hdfs-file-system">Start/stop the hdfs file system</h2>
<p><code>sudo /usr/local/hadoop/bin/hdfs namenode -format</code> - format the namenode<br><code>sudo /usr/local/hadoop/sbin/start-dfs.sh</code><br><code>sudo /usr/local/hadoop/sbin/stop-dfs.sh</code>  </p>
<p>By default, HDFS NameNode can be accessed using <a href="http://localhost:9870/">http://localhost:9870/</a></p>
<h2 id="start-stop-the-yarn">Start/Stop the YARN</h2>
<p><code>sudo /usr/local/hadoop/sbin/start-yarn.sh</code><br><code>sudo /usr/local/hadoop/sbin/stop-yarn.sh</code></p>
<p>By default, yarn resource manager can be access in <a href="http://localhost:8088/">http://localhost:8088/</a></p>

	
	</div>

<div id="footer" class="d-flex justify-content-center"></div>

</body>
</html>